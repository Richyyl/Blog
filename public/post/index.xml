<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Upsupervised Learnings</title>
    <link>/post/</link>
    <description>Recent content in Posts on Upsupervised Learnings</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Logo copyright of zen pencils</copyright>
    <lastBuildDate>Fri, 15 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Big Data London!</title>
      <link>/post/big-data-london/</link>
      <pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/big-data-london/</guid>
      <description>Anyone who’s read The Hitchhikers Guide to The Galaxy, or seen the film, will know the seminal quote “Space is big. Really big. You just won’t believe how vastly hugely mindbogglingly big it is.”. &#34;Well apparently space has a new competitor for sheer size, and that’s data!
Every year a mass of people descend on the Olympia conference center in Hammersmith, London for the Big Data London (BDL) conference. This year I was lucky enough to attend as an exhibitor with The Oakland Group, a data led consultancy that I currently work for!</description>
    </item>
    
    <item>
      <title>Building an ETL pipeline with Azure Batch</title>
      <link>/post/2019-11-01-building-an-etl-pipeline-in-azure.en/building-an-etl-pipeline-with-azure-batch/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-11-01-building-an-etl-pipeline-in-azure.en/building-an-etl-pipeline-with-azure-batch/</guid>
      <description>So, this is my first post in a long while, partly due to a busy summer and partly due to shifting jobs (which added to the busyness!). Since June I’ve been working as a data scientist / dev at a small, but rapidly growing, tech consultancy, which so far has lead to me learning tonnes of new skills and working on some interesting projects. It’s because of this jump that I can actually write this post, as one project was the automation of a very manual, local process through the use of the Azure platform.</description>
    </item>
    
    <item>
      <title>Intro to Spark and building an AWS EMR cluster</title>
      <link>/post/2019-05-22-building-a-data-science-environment-with-aws-emr.en/building-a-data-science-environment-with-aws-emr/</link>
      <pubDate>Sat, 08 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-05-22-building-a-data-science-environment-with-aws-emr.en/building-a-data-science-environment-with-aws-emr/</guid>
      <description>This post has mainly been written for me, so that in the future I have a general reference guide for spark and so I don’t have to piece together the various bits I’ve found strewn across the internet in order to build an EMR instance that I like. Also I originally wanted to build this to test whether reticulate could be used to link in with Spark on an EMR (elastic map reduce) cluster.</description>
    </item>
    
    <item>
      <title>Football Modelling part 3 - Team predictions</title>
      <link>/post/2019-04-21-football-modelling-part-3-team-predictions/football-modelling-part-3-team-predictions/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-21-football-modelling-part-3-team-predictions/football-modelling-part-3-team-predictions/</guid>
      <description>This document will serve as the final part (part 3) of the premier league analysis / modelling, and will be focussed on the player data collected in part one, which will then be aggregated inot teams and used for predicting some old matches.
As before, first thing to do is load the required packages, for this piece the requirements should be filled by both the tidyverse, for cleaning / iterating, and rvest to scrape some fixtures.</description>
    </item>
    
    <item>
      <title>Football Modelling part 2 - EDA and Modelling</title>
      <link>/post/2019-04-14-football-modelling-part-2-eda-and-modelling/football-modelling-part-2-eda-and-modelling/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-14-football-modelling-part-2-eda-and-modelling/football-modelling-part-2-eda-and-modelling/</guid>
      <description>This document will serve as part two, focussing on exploring the data collected in part one and building the final model to test on player data, as such it will be focussed at the team level.
As before, first thing to do is load the required packages, for this piece the requirements should be filled by both the tidyverse and tidymodels packages, as well as the required model packages and ggrepel / gghighlight to add tweaks to charts.</description>
    </item>
    
    <item>
      <title>Football Modelling part 1 - Web scraping</title>
      <link>/post/2019-04-07-football-modelling-part-1-data-collection/football-modelling-part-1-web-scraping/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-07-football-modelling-part-1-data-collection/football-modelling-part-1-web-scraping/</guid>
      <description>This piece of work will focus on scraping football data and using it to build a statistical model to predict the outcomes of premier league matches in England. It will be comprised of three parts, all aiming to use skills I have acquired over the past couple of years.
Part one: Obtaining data on both current players (past three years) and teams for the last four seasons of matches</description>
    </item>
    
    <item>
      <title>Clustering comparison</title>
      <link>/post/2018-07-28-clustering-comparison/p-hacking/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-07-28-clustering-comparison/p-hacking/</guid>
      <description>IntroThis short post is an attempt to compare two commonly used clustering methods, hierarchical and k means, utilising a wheat seeds data set from the online machine learning repository AnalysisFirst thing as always is to load packages, with a mix of cleaning, clustering and graphing packages for this analysis.
library(tidyverse)library(clustree)library(cluster)library(scales)library(gridExtra)library(devtools)library(gganimate)Now its time to load in the data set and tidy it up.</description>
    </item>
    
    <item>
      <title>The life of Sam Vimes - A Discworld NLP project</title>
      <link>/post/2018-04-28-the-life-of-sam-vimes-a-discworld-nlp-project.en/the-life-of-sam-vimes-a-discworld-nlp-project/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-04-28-the-life-of-sam-vimes-a-discworld-nlp-project.en/the-life-of-sam-vimes-a-discworld-nlp-project/</guid>
      <description>I’ve never been a huge reader, though when I do tend to get into a book it’s usually part of a larger series (ASOIAF, Harry Potter, LoTR etc). By far my favorite series of books belongs to the collection know as discworld novels, written by Sir Terry Pratchett. Between 1983 and 2015 he wrote 41 novels all surrounding a single universe, where a giant tortoise holding up a disc shaped world roamed the sky’s.</description>
    </item>
    
  </channel>
</rss>